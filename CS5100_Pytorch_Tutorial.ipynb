{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaeekaayyyyyy/pytorch/blob/main/CS5100_Pytorch_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXRrigkRDs36"
      },
      "source": [
        "# CS5100 - Foundations of Artificial Intelligence\n",
        "## Fall 2025\n",
        "\n",
        "\n",
        "## Pytorch Tutorial\n",
        "\n",
        "\n",
        "\n",
        "**Instructor:** Amir Tahmasebi\n",
        "\n",
        "**Prerequisites:** Basic Python (variables, lists, functions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62uCtydmDs38"
      },
      "source": [
        "## **Part 1: Introduction & Setup**\n",
        "\n",
        "### **What is PyTorch?**\n",
        "\n",
        "PyTorch is an open-source library developed by Facebook's AI Research lab. At its core, it's a library for numerical computation, similar to NumPy, but with two massive advantages:\n",
        "\n",
        "1.  **GPU Acceleration:** It can perform calculations on Graphics Processing Units (GPUs), making it incredibly fast for the parallel computations common in AI.\n",
        "2.  **Automatic Differentiation:** It has a built-in system called `autograd` that can automatically calculate the gradients (derivatives) of functions. This is the engine that powers the training of modern neural networks, but it's also a powerful tool for any optimization problem.\n",
        "\n",
        "In the context of AIMA **[“Artificial Intelligence: A Modern Approach” by Stuart Russell and Peter Norvig]**, you can think of PyTorch as a powerful toolkit for representing and manipulating the states, actions, costs, and models that are central to AI agents.\n",
        "\n",
        "### **Setup and \"Hello World\"**\n",
        "\n",
        "Let's make sure you have PyTorch installed and import it. The standard convention is to import it as `torch`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.615011Z",
          "start_time": "2025-09-30T00:13:43.612143Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTIz-mfBDs39",
        "outputId": "648c8458-2593-452f-9bd4-123b6a7a97d7"
      },
      "source": [
        "# This is a standard cell in a Jupyter Notebook.\n",
        "# Press Shift+Enter to run it.\n",
        "\n",
        "import torch\n",
        "import numpy as np # We'll use numpy to show interoperability\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(\"PyTorch is installed and ready to go!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "PyTorch is installed and ready to go!\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_1gKycpDs3-"
      },
      "source": [
        "## **Part 2: The Core of PyTorch: Tensors**\n",
        "\n",
        "Everything in PyTorch revolves around the **Tensor**. A tensor is a multi-dimensional array, just like a NumPy `ndarray`.\n",
        "\n",
        "* **Scalar:** A single number (0-dimensional tensor).\n",
        "* **Vector:** A 1D array of numbers (1-dimensional tensor).\n",
        "* **Matrix:** A 2D array of numbers (2-dimensional tensor).\n",
        "* **Tensor:** The general term for an N-dimensional array.\n",
        "\n",
        "\n",
        "### **Creating Tensors**\n",
        "\n",
        "You can create tensors in many ways."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.641822Z",
          "start_time": "2025-09-30T00:13:43.636911Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLBtzQHMDs3-",
        "outputId": "e2a11c56-e917-4cd6-8f2b-89db5d91873a"
      },
      "source": [
        "# Create a tensor from a Python list\n",
        "my_list = [[1, 2, 3], [4, 5, 6]]\n",
        "my_tensor = torch.tensor(my_list)\n",
        "print(\"Tensor from list:\\n\", my_tensor)\n",
        "\n",
        "# Create a tensor from a NumPy array\n",
        "my_numpy_array = np.array([[7, 8], [9, 10]])\n",
        "tensor_from_numpy = torch.from_numpy(my_numpy_array)\n",
        "print(\"\\nTensor from NumPy array:\\n\", tensor_from_numpy)\n",
        "\n",
        "# You can also create tensors with specific values\n",
        "zeros_tensor = torch.zeros(2, 3) # 2 rows, 3 columns\n",
        "print(\"\\nTensor of zeros:\\n\", zeros_tensor)\n",
        "\n",
        "ones_tensor = torch.ones(3, 2) # 3 rows, 2 columns\n",
        "print(\"\\nTensor of ones:\\n\", ones_tensor)\n",
        "\n",
        "random_tensor = torch.rand(2, 2) # Random values between 0 and 1\n",
        "print(\"\\nRandom tensor:\\n\", random_tensor)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor from list:\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "Tensor from NumPy array:\n",
            " tensor([[ 7,  8],\n",
            "        [ 9, 10]])\n",
            "\n",
            "Tensor of zeros:\n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "\n",
            "Tensor of ones:\n",
            " tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "\n",
            "Random tensor:\n",
            " tensor([[0.5972, 0.9587],\n",
            "        [0.8740, 0.5140]])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmNSTPWpDs3-"
      },
      "source": [
        "### **Tensor Attributes**\n",
        "\n",
        "Tensors have important attributes that tell you about their structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.664850Z",
          "start_time": "2025-09-30T00:13:43.661969Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMp99FKvDs3-",
        "outputId": "e9f47188-4988-4b65-b6e8-d6e5d4df0f71"
      },
      "source": [
        "# Let's inspect our random_tensor from above\n",
        "print(\"Our random tensor:\\n\", random_tensor)\n",
        "\n",
        "# .shape tells you the dimensions of the tensor\n",
        "print(f\"\\nShape: {random_tensor.shape}\")\n",
        "\n",
        "# .dtype tells you the data type of the elements\n",
        "print(f\"Data type: {random_tensor.dtype}\")\n",
        "\n",
        "# .device tells you where the tensor is stored (CPU or GPU)\n",
        "print(f\"Device: {random_tensor.device}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our random tensor:\n",
            " tensor([[0.5972, 0.9587],\n",
            "        [0.8740, 0.5140]])\n",
            "\n",
            "Shape: torch.Size([2, 2])\n",
            "Data type: torch.float32\n",
            "Device: cpu\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGHFldsBDs3_"
      },
      "source": [
        "You can explicitly set the data type. This is very important in AI for managing memory and precision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.688147Z",
          "start_time": "2025-09-30T00:13:43.685156Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQGzHxGoDs3_",
        "outputId": "26fb2734-ff1b-45a0-bf40-68dd82f3577a"
      },
      "source": [
        "float_tensor = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
        "print(f\"Float tensor: {float_tensor} with dtype {float_tensor.dtype}\")\n",
        "\n",
        "long_tensor = torch.tensor([0.1, 2, 3], dtype=torch.long) # 64-bit integer\n",
        "print(f\"Long tensor: {long_tensor} with dtype {long_tensor.dtype}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Float tensor: tensor([1., 2., 3.]) with dtype torch.float32\n",
            "Long tensor: tensor([0, 2, 3]) with dtype torch.int64\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqxAHlw0Ds3_"
      },
      "source": [
        "### **Indexing and Slicing**\n",
        "\n",
        "If you know NumPy or Python list slicing, this will be very familiar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.713140Z",
          "start_time": "2025-09-30T00:13:43.709958Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tbHYfdRDs3_",
        "outputId": "78b0f7b1-76b7-4ea8-a61b-3c72448928d5"
      },
      "source": [
        "# Let's create a tensor to play with\n",
        "data = torch.tensor([\n",
        "    [10, 20, 30],\n",
        "    [40, 50, 60],\n",
        "    [70, 80, 90]\n",
        "])\n",
        "\n",
        "# Get the first row\n",
        "print(\"First row:\", data[0])\n",
        "\n",
        "# Get a single element (at row 1, column 2) -> 60\n",
        "print(\"Element at (1, 2):\", data[1, 2]) # Note the comma notation\n",
        "\n",
        "# Get the last column\n",
        "# The ':' means \"all rows\"\n",
        "print(\"Last column:\\n\", data[:, 2])\n",
        "\n",
        "# Slice to get a sub-matrix (top-left 2x2)\n",
        "print(\"Top-left 2x2 sub-matrix:\\n\", data[:2, :2])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([10, 20, 30])\n",
            "Element at (1, 2): tensor(60)\n",
            "Last column:\n",
            " tensor([30, 60, 90])\n",
            "Top-left 2x2 sub-matrix:\n",
            " tensor([[10, 20],\n",
            "        [40, 50]])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAFPmPGUDs3_"
      },
      "source": [
        "---\n",
        "### ✍️ **Exercise 2.1: Your Turn! **\n",
        "\n",
        "1.  Create a 3x4 tensor filled with the integer `5`.\n",
        "2.  Print its shape and data type.\n",
        "3.  Select and print the element in the second row, third column.\n",
        "4.  Select and print the entire second row.\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.738405Z",
          "start_time": "2025-09-30T00:13:43.736665Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6twSCSKmDs4A",
        "outputId": "662e492a-9a0e-40dc-e350-19a56d5a9621"
      },
      "cell_type": "code",
      "source": [
        "# Exercise 2.1\n",
        "\n",
        "# 1. Create a 3x4 tensor filled with the integer 5\n",
        "my_tensor = torch.full((3, 4), 5)\n",
        "print(\"Tensor filled with 5:\")\n",
        "print(my_tensor)\n",
        "\n",
        "# 2. Print its shape and data type\n",
        "print(f\"\\nShape: {my_tensor.shape}\")\n",
        "print(f\"Data type: {my_tensor.dtype}\")\n",
        "\n",
        "# 3. Select and print the element in the second row, third column\n",
        "element = my_tensor[1, 2]\n",
        "print(f\"\\nElement at row 2, column 3: {element}\")\n",
        "\n",
        "# 4. Select and print the entire second row\n",
        "second_row = my_tensor[1]\n",
        "print(f\"\\nEntire second row: {second_row}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor filled with 5:\n",
            "tensor([[5, 5, 5, 5],\n",
            "        [5, 5, 5, 5],\n",
            "        [5, 5, 5, 5]])\n",
            "\n",
            "Shape: torch.Size([3, 4])\n",
            "Data type: torch.int64\n",
            "\n",
            "Element at row 2, column 3: 5\n",
            "\n",
            "Entire second row: tensor([5, 5, 5, 5])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ThkqKqIDs4A"
      },
      "source": [
        "## **Part 3: Tensor Operations**\n",
        "\n",
        "PyTorch provides a rich library of operations to perform on tensors.\n",
        "\n",
        "### **Basic Mathematical Operations**\n",
        "\n",
        "Operations are typically element-wise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.746072Z",
          "start_time": "2025-09-30T00:13:43.742902Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gX9bg7yDs4A",
        "outputId": "420eb4c3-0275-490e-889a-ce050fd757d9"
      },
      "source": [
        "a = torch.tensor([[1, 2], [3, 4]])\n",
        "b = torch.tensor([[10, 20], [30, 40]])\n",
        "\n",
        "# Addition\n",
        "print(\"Addition:\\n\", a + b)\n",
        "# Or use the function form\n",
        "print(\"Addition (function):\\n\", torch.add(a, b))\n",
        "\n",
        "# Element-wise multiplication\n",
        "print(\"\\nElement-wise multiplication:\\n\", a * b)\n",
        "# Or use the function\n",
        "print(\"\\nFunction multiplication:\\n\", torch.mul(a,b))\n",
        "\n",
        "# Division\n",
        "print(\"\\nDivision:\\n\", b / a)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Addition:\n",
            " tensor([[11, 22],\n",
            "        [33, 44]])\n",
            "Addition (function):\n",
            " tensor([[11, 22],\n",
            "        [33, 44]])\n",
            "\n",
            "Element-wise multiplication:\n",
            " tensor([[ 10,  40],\n",
            "        [ 90, 160]])\n",
            "\n",
            "Function multiplication:\n",
            " tensor([[ 10,  40],\n",
            "        [ 90, 160]])\n",
            "\n",
            "Division:\n",
            " tensor([[10., 10.],\n",
            "        [10., 10.]])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22Ol-7WpDs4A"
      },
      "source": [
        "### **Matrix Multiplication**\n",
        "\n",
        "This is one of the most important operations in all of AI. In AIMA, you might use it for state transitions. In deep learning, it's fundamental."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.762466Z",
          "start_time": "2025-09-30T00:13:43.759695Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV2-UNyKDs4A",
        "outputId": "c87e85ed-0827-46aa-fc9d-f77b68feb060"
      },
      "source": [
        "mat1 = torch.tensor([[1, 2], [3, 4]])\n",
        "mat2 = torch.tensor([[5, 6], [7, 8]])\n",
        "\n",
        "# The '@' symbol is the standard way to do matrix multiplication\n",
        "mat_mul_result = mat1 @ mat2\n",
        "print(\"Matrix multiplication result:\\n\", mat_mul_result)\n",
        "\n",
        "# Or you can use torch.matmul()\n",
        "mat_mul_result_func = torch.matmul(mat1, mat2)\n",
        "print(\"\\nSame result using torch.matmul():\\n\", mat_mul_result_func)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix multiplication result:\n",
            " tensor([[19, 22],\n",
            "        [43, 50]])\n",
            "\n",
            "Same result using torch.matmul():\n",
            " tensor([[19, 22],\n",
            "        [43, 50]])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf2OOVnSDs4A"
      },
      "source": [
        "**Remember the rule for matrix multiplication:** The number of columns in the first matrix must equal the number of rows in the second matrix. $(m \\times n) @ (n \\times p) \\rightarrow (m \\times p)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWWQ-iAmDs4A"
      },
      "source": [
        "### **Reshaping Tensors**\n",
        "\n",
        "Sometimes you need to change the shape of a tensor without changing its data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.782037Z",
          "start_time": "2025-09-30T00:13:43.779133Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTvzvfA0Ds4A",
        "outputId": "79730eac-2254-4634-c0f3-263748e6111a"
      },
      "source": [
        "original_tensor = torch.arange(1, 13) # A vector of numbers from 1 to 12\n",
        "print(\"Original tensor:\", original_tensor)\n",
        "print(\"Original shape:\", original_tensor.shape)\n",
        "\n",
        "# Reshape it into a 3x4 matrix\n",
        "reshaped_tensor = original_tensor.reshape(3, 4)\n",
        "print(\"\\nReshaped to 3x4:\\n\", reshaped_tensor)\n",
        "print(\"New shape:\", reshaped_tensor.shape)\n",
        "\n",
        "# You can also use .view(). It's similar but shares the underlying data in a more direct way.\n",
        "# -1 is a useful trick to let PyTorch infer the dimension.\n",
        "viewed_tensor = original_tensor.view(2, -1) # Infer the number of columns\n",
        "print(\"\\nViewed as 2 rows:\\n\", viewed_tensor)\n",
        "print(\"Viewed shape:\", viewed_tensor.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor: tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n",
            "Original shape: torch.Size([12])\n",
            "\n",
            "Reshaped to 3x4:\n",
            " tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "New shape: torch.Size([3, 4])\n",
            "\n",
            "Viewed as 2 rows:\n",
            " tensor([[ 1,  2,  3,  4,  5,  6],\n",
            "        [ 7,  8,  9, 10, 11, 12]])\n",
            "Viewed shape: torch.Size([2, 6])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPrle3Q6Ds4A"
      },
      "source": [
        "---\n",
        "### ✍️ **Exercise 3.1: Your Turn!**\n",
        "\n",
        "You have two tensors representing item quantities and their per-item costs.\n",
        "\n",
        "```python\n",
        "quantities = torch.tensor([[5, 2], [10, 3], [1, 8]]) # 3 products, 2 stores\n",
        "costs = torch.tensor([100, 200]) # Cost per item for store 1 and store 2\n",
        "```\n",
        "Your goal is to calculate the total value of inventory for each product. This can be done with an element-wise multiplication.\n",
        "\n",
        "1.  Calculate the total value per product per store using element-wise multiplication.\n",
        "2.  Then, calculate the sum of values for *each product* across both stores. The final result should be a tensor of shape `[3]`. (Hint: look up `torch.sum()`).\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.792908Z",
          "start_time": "2025-09-30T00:13:43.791397Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqLJ2vXGDs4A",
        "outputId": "d33933d9-ff3f-448b-f66a-03fd77df987d"
      },
      "cell_type": "code",
      "source": [
        "quantities = torch.tensor([[5, 2], [10, 3], [1, 8]])\n",
        "costs = torch.tensor([100, 200])\n",
        "\n",
        "total_per_store = quantities * costs\n",
        "total_per_product = torch.sum(total_per_store, dim=1)\n",
        "\n",
        "print(\"\\n Total per store:\",total_per_store)\n",
        "print(\"\\n Total per product:\",total_per_product)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total per store: tensor([[ 500,  400],\n",
            "        [1000,  600],\n",
            "        [ 100, 1600]])\n",
            "\n",
            " Total per product: tensor([ 900, 1600, 1700])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTwJAVshDs4A"
      },
      "source": [
        "## **Part 4: Connecting Tensors to AI (AIMA)**\n",
        "\n",
        "Tensors aren't just for numbers; they are perfect for representing the environments and knowledge in AI agents.\n",
        "\n",
        "### **Representing a State Space: A Grid World**\n",
        "\n",
        "In AIMA, many search and reinforcement learning problems (like Chapter 17 & 21) use a grid world. A tensor is the perfect way to represent this!\n",
        "\n",
        "Let's define a simple 5x5 grid world where:\n",
        "* `0`: Empty, traversable path\n",
        "* `1`: A wall (impassable)\n",
        "* `8`: The agent's starting position\n",
        "* `9`: The goal position"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.809358Z",
          "start_time": "2025-09-30T00:13:43.806701Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqzga4i4Ds4A",
        "outputId": "6afa5ebd-5013-431d-d05d-3d273c763e63"
      },
      "source": [
        "# Create a 5x5 grid of zeros\n",
        "grid_world = torch.zeros(5, 5, dtype=torch.int)\n",
        "\n",
        "# Place some walls\n",
        "grid_world[1, 1:4] = 1 # A horizontal wall\n",
        "grid_world[3, 2] = 1   # A single wall block\n",
        "\n",
        "# Place the start and goal\n",
        "start_pos = (0, 0)\n",
        "goal_pos = (4, 4)\n",
        "grid_world[start_pos] = 8\n",
        "grid_world[goal_pos] = 9\n",
        "\n",
        "print(\"Our Grid World State Space:\\n\")\n",
        "print(grid_world)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our Grid World State Space:\n",
            "\n",
            "tensor([[8, 0, 0, 0, 0],\n",
            "        [0, 1, 1, 1, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 9]], dtype=torch.int32)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHFipIoNDs4A"
      },
      "source": [
        "Now, we can easily check the state of any cell. A search algorithm like A* could use this representation to check for walls."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.823016Z",
          "start_time": "2025-09-30T00:13:43.820127Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AovmutVDs4A",
        "outputId": "55f5b23b-663e-433a-f9ae-c92cd756c22f"
      },
      "source": [
        "# Is the position (1, 2) a wall?\n",
        "is_wall = (grid_world[1, 2] == 1)\n",
        "print(f\"\\nIs the cell (1, 2) a wall? {is_wall}\")\n",
        "\n",
        "# Where is the agent?\n",
        "agent_pos_indices = (grid_world == 8).nonzero()\n",
        "print(f\"The agent is at position: {agent_pos_indices}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Is the cell (1, 2) a wall? True\n",
            "The agent is at position: tensor([[0, 0]])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7faCzQxDs4B"
      },
      "source": [
        "### **Representing Utilities or Costs**\n",
        "\n",
        "In problems like value iteration or policy iteration, each state in the world has a \"utility\" or \"value\". We can represent this with another tensor of the same shape.\n",
        "\n",
        "Let's imagine we're running an algorithm and have calculated some utility values for our grid world."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.837353Z",
          "start_time": "2025-09-30T00:13:43.834477Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xie9_fFjDs4B",
        "outputId": "3aa41279-27ff-4d60-8d0c-8e2cad9cffe3"
      },
      "source": [
        "# Initialize utilities for all states to 0.0\n",
        "# Use float because utilities are often not integers.\n",
        "utilities = torch.zeros(5, 5, dtype=torch.float32)\n",
        "\n",
        "# Let's say we've calculated some utilities\n",
        "utilities[4, 4] = 10.0  # Goal state has high utility\n",
        "utilities[4, 3] = 7.5\n",
        "utilities[3, 4] = 7.5\n",
        "utilities[0, 1] = -5.0 # A state to avoid\n",
        "\n",
        "print(\"Utility Tensor:\\n\")\n",
        "print(utilities)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utility Tensor:\n",
            "\n",
            "tensor([[ 0.0000, -5.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  7.5000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  7.5000, 10.0000]])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alZJUGT3Ds4B"
      },
      "source": [
        "An AI agent could use this utility tensor to decide which way to move. From position (3,3), it would look at the utilities of its neighbors (3,4), (3,2), (2,3), and (4,3) to choose the best action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMJr66kHDs4B"
      },
      "source": [
        "---\n",
        "### ✍️ **Exercise 4.1: Your Turn!**\n",
        "\n",
        "1.  Create a new `6x6` grid world tensor called `my_grid`.\n",
        "2.  Set the entire border (all rows/columns on the edge) to be walls (`1`).\n",
        "3.  Place a start state (`8`) at position `(1, 1)` and a goal state (`9`) at `(4, 4)`.\n",
        "4.  Print the resulting grid.\n",
        "---"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.851052Z",
          "start_time": "2025-09-30T00:13:43.849348Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYwGvKUADs4B",
        "outputId": "34a2cf9c-81b0-4609-8c4e-f1f8fd8a8f16"
      },
      "cell_type": "code",
      "source": [
        "# Exercise 4.1: Create a 6x6 grid world with bordered walls\n",
        "\n",
        "# 1. Create a new 6x6 grid world tensor called my_grid\n",
        "my_grid = torch.zeros(6, 6, dtype=torch.int)\n",
        "\n",
        "# 2. Set the entire border (all rows/columns on the edge) to be walls (1)\n",
        "my_grid[0, :] = 1  # Top row\n",
        "my_grid[5, :] = 1  # Bottom row\n",
        "my_grid[:, 0] = 1  # Left column\n",
        "my_grid[:, 5] = 1  # Right column\n",
        "\n",
        "# 3. Place a start state (8) at position (1, 1) and a goal state (9) at (4, 4)\n",
        "my_grid[1, 1] = 8  # Start position\n",
        "my_grid[4, 4] = 9  # Goal position\n",
        "\n",
        "# 4. Print the resulting grid\n",
        "print(\"6x6 Grid World with Border Walls:\")\n",
        "print(my_grid)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6x6 Grid World with Border Walls:\n",
            "tensor([[1, 1, 1, 1, 1, 1],\n",
            "        [1, 8, 0, 0, 0, 1],\n",
            "        [1, 0, 0, 0, 0, 1],\n",
            "        [1, 0, 0, 0, 0, 1],\n",
            "        [1, 0, 0, 0, 9, 1],\n",
            "        [1, 1, 1, 1, 1, 1]], dtype=torch.int32)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR8Un6E1Ds4B"
      },
      "source": [
        "## **Part 5: The \"Magic\" - Automatic Differentiation**\n",
        "\n",
        "This is the feature that truly sets PyTorch apart from a library like NumPy. `autograd` can automatically compute the gradient (or derivative) of a function.\n",
        "\n",
        "**Why is this important for AI?**\n",
        "Many AI problems, from simple search to training massive neural networks, are **optimization problems**. We define a \"cost\" or \"error\" function, and we want to find the input parameters that *minimize* this cost. The gradient tells us the direction of steepest ascent of the function, so moving in the *opposite* direction helps us find the minimum.\n",
        "\n",
        "Let's see it in action with a simple mathematical function: $y = 3x^2 + 5$.\n",
        "The derivative is $\\frac{dy}{dx} = 6x$. At $x=2$, the gradient should be $6 \\times 2 = 12$.\n",
        "\n",
        "Let's see if PyTorch agrees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.863292Z",
          "start_time": "2025-09-30T00:13:43.860267Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g8M4dLhDs4B",
        "outputId": "9d6d3b8d-f367-436e-bdd2-09233698d4b5"
      },
      "source": [
        "# To calculate gradients, we need to tell PyTorch.\n",
        "# We do this by setting requires_grad=True.\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "# Define our function\n",
        "y = 3 * x**2 + 5\n",
        "\n",
        "print(\"x:\", x)\n",
        "print(\"y:\", y)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tensor(2., requires_grad=True)\n",
            "y: tensor(17., grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLYq1hj-Ds4B"
      },
      "source": [
        "Now, the magic step. We call `.backward()` on our output `y`. This calculates the gradients of `y` with respect to all tensors that have `requires_grad=True` (in this case, just `x`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.889208Z",
          "start_time": "2025-09-30T00:13:43.885474Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThUKEC8HDs4B",
        "outputId": "63f5ccdb-d4f6-4c6b-92cb-c6a0cf54d11d"
      },
      "source": [
        "# Calculate the gradients\n",
        "y.backward()\n",
        "\n",
        "# The gradient is stored in the .grad attribute of the tensor\n",
        "print(\"\\nThe gradient of y with respect to x at x=2 is:\", x.grad)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The gradient of y with respect to x at x=2 is: tensor(12.)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBqQN0OJDs4B"
      },
      "source": [
        "It works perfectly! PyTorch calculated that the gradient is 12.\n",
        "\n",
        "Imagine your function isn't $y = 3x^2 + 5$, but a function with millions of parameters representing a complex AI model. PyTorch's `autograd` can still compute the gradients automatically, which is what enables us to train these models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YPCqxaEDs4B"
      },
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "9emGPVlTDs4B"
      },
      "cell_type": "markdown",
      "source": [
        "# **Part 6: Neural Network Modules (torch.nn)**\n",
        "In PyTorch, neural networks are built using the torch.nn module. At their core, neural networks are just functions made of layers that transform inputs into outputs. PyTorch makes building and training them much easier with a few key components:\n",
        "\n",
        "1.  **nn.Module**: This is the base class for all neural network models. You create your own network by subclassing nn.Module and defining layers inside __init__. The forward method describes how data flows through those layers.\n",
        "2.  **nn.Linear**: A layer is a transformation applied to the input.Example: nn.Linear(in_features, out_features) applies a weighted sum plus a bias. PyTorch automatically creates and tracks the weights and biases for you.\n",
        "\n",
        "Now, we’ll build a network to learn the function:\n",
        "$y = 3x_1 + 2x_2 + 1$"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.935609Z",
          "start_time": "2025-09-30T00:13:43.904657Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk20LqVeDs4B",
        "outputId": "9c42c057-b770-4aa2-e4ad-2c8541c71662"
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Step 1: Generate Data\n",
        "# Create 100 random samples with 2 features each (values between 0 and 10)\n",
        "X = torch.rand(100, 2) * 10\n",
        "\n",
        "# Define target outputs using the linear relation: y = 3*x1 + 2*x2 + 1\n",
        "Y = 3*X[:,0:1] + 2*X[:,1:2] + 1\n",
        "\n",
        "\n",
        "# Step 2: Define Model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        # First fully connected layer: 2 inputs → 16 hidden units\n",
        "        self.fc1 = nn.Linear(2, 16)\n",
        "        # Second fully connected layer: 16 hidden units → 1 output\n",
        "        self.fc2 = nn.Linear(16, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through first layer + ReLU activation\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        # Pass through second layer to get final prediction\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the model\n",
        "model = SimpleNN()\n",
        "\n",
        "\n",
        "# Step 3: Loss + Optimizer\n",
        "# Mean Squared Error loss is suitable for regression\n",
        "criterion = nn.MSELoss()\n",
        "# Adam optimizer will update the weights during training\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "# Step 4: Training Loop\n",
        "for epoch in range(200):\n",
        "    # Forward pass: compute predictions\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # Compute loss between predictions and true labels\n",
        "    loss = criterion(y_pred, Y)\n",
        "\n",
        "    # Reset gradients to zero before backpropagation\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights based on gradients\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print loss every 20 epochs to track progress\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
        "\n",
        "\n",
        "# Step 5: Test Model\n",
        "# Create some new test samples\n",
        "test = torch.tensor([[4.0, 7.0],\n",
        "                     [1.5, 2.5]])\n",
        "\n",
        "# Run model on test data and detach from computation graph\n",
        "print(\"Predictions:\", model(test).detach())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss = 754.9328002929688\n",
            "Epoch 20: loss = 354.5280456542969\n",
            "Epoch 40: loss = 11.316622734069824\n",
            "Epoch 60: loss = 6.324686050415039\n",
            "Epoch 80: loss = 2.095747470855713\n",
            "Epoch 100: loss = 0.7582637667655945\n",
            "Epoch 120: loss = 0.41391587257385254\n",
            "Epoch 140: loss = 0.2952936887741089\n",
            "Epoch 160: loss = 0.2249375581741333\n",
            "Epoch 180: loss = 0.17231830954551697\n",
            "Predictions: tensor([[26.8569],\n",
            "        [10.7449]])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "iiGqg-rmDs4G"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### ✍️ **Exercise 6.1: Build and Train Your Own Neural Network**\n",
        "\n",
        "You are given synthetic data where the target output is defined as:\n",
        "$y = 4x_1 - 2x_2 + 3$\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Input data: 100 samples, each with 2 features\n",
        "X = torch.rand(100, 2) * 10\n",
        "\n",
        "# Target outputs using the linear relation\n",
        "Y = 4*X[:,0:1] - 2*X[:,1:2] + 3\n",
        "```\n",
        "Your task is to build and train a simple neural network using PyTorch.\n",
        "\n",
        "1. Define a model with:\n",
        "   - One hidden layer of size 16 (`nn.Linear`)\n",
        "   - ReLU activation\n",
        "   - One output neuron\n",
        "2. Use **MSELoss** as your loss function.\n",
        "3. Use the **Adam optimizer** with a learning rate of `0.01`.\n",
        "4. Train your model for 200 epochs. Print the loss every 20 epochs to see training progress.\n",
        "5. Test your trained model on the following samples:\n",
        "\n",
        "```python\n",
        "test = torch.tensor([[6.0, 2.0],\n",
        "                     [1.5, 5.0]])\n",
        "```\n",
        "Goal: After training, your predictions should be close to the true values of\n",
        "$y = 4x_1 - 2x_2 + 3$\n",
        "for the test inputs."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.943736Z",
          "start_time": "2025-09-30T00:13:43.942384Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBdI2X23Ds4G",
        "outputId": "882c80a5-7173-4526-b44f-f26ec235ddc2"
      },
      "cell_type": "code",
      "source": [
        "# Exercise 6.1: Build and Train Your Own Neural Network for y = 4*x1 - 2*x2 + 3\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Step 1: Generate Data\n",
        "X = torch.rand(100, 2) * 10\n",
        "Y = 4*X[:, 0:1] - 2*X[:, 1:2] + 3\n",
        "\n",
        "# Step 2: Define Model\n",
        "class MyNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 16)  # Hidden layer: 2 inputs -> 16 units\n",
        "        self.fc2 = nn.Linear(16, 1)  # Output layer: 16 units -> 1 output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))  # ReLU activation\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Create model instance\n",
        "model = MyNN()\n",
        "\n",
        "# Step 3: Loss and Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Step 4: Training Loop\n",
        "for epoch in range(200):\n",
        "    y_pred = model(X)\n",
        "    loss = criterion(y_pred, Y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
        "\n",
        "# Step 5: Test Model\n",
        "test = torch.tensor([[6.0, 2.0], [1.5, 5.0]])\n",
        "print(\"\\nPredictions:\", model(test).detach())\n",
        "print(\"\\nExpected values:\")\n",
        "print(\"For [6.0, 2.0]: y = 4*6 - 2*2 + 3 = 23\")\n",
        "print(\"For [1.5, 5.0]: y = 4*1.5 - 2*5 + 3 = -1\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss = 353.8475036621094\n",
            "Epoch 20: loss = 261.6234436035156\n",
            "Epoch 40: loss = 133.09243774414062\n",
            "Epoch 60: loss = 21.518943786621094\n",
            "Epoch 80: loss = 1.4773712158203125\n",
            "Epoch 100: loss = 0.1772811859846115\n",
            "Epoch 120: loss = 0.13464301824569702\n",
            "Epoch 140: loss = 0.10397567600011826\n",
            "Epoch 160: loss = 0.09014996886253357\n",
            "Epoch 180: loss = 0.07865042984485626\n",
            "\n",
            "Predictions: tensor([[23.2281],\n",
            "        [-1.0787]])\n",
            "\n",
            "Expected values:\n",
            "For [6.0, 2.0]: y = 4*6 - 2*2 + 3 = 23\n",
            "For [1.5, 5.0]: y = 4*1.5 - 2*5 + 3 = -1\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIV5C1vdDs4G"
      },
      "source": [
        "## **Part 7: Quick Look at GPU & Wrap-up**\n",
        "\n",
        "The final key feature of PyTorch is its ability to run on a GPU for massive speedups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.961602Z",
          "start_time": "2025-09-30T00:13:43.950463Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtJ7WLaODs4G",
        "outputId": "23fdb225-c2db-4271-8707-d8e6570084d4"
      },
      "source": [
        "# First, check if a CUDA-enabled GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available! We'll use the GPU.\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, using CPU.\")\n",
        "\n",
        "# You can move any tensor to the chosen device using .to()\n",
        "# Let's create a large tensor on the CPU\n",
        "large_tensor_cpu = torch.randn(1000, 1000)\n",
        "\n",
        "# Now move it to the GPU (if available)\n",
        "large_tensor_gpu = large_tensor_cpu.to(device)\n",
        "\n",
        "print(f\"\\nlarge_tensor_cpu is on device: {large_tensor_cpu.device}\")\n",
        "print(f\"large_tensor_gpu is on device: {large_tensor_gpu.device}\")\n",
        "\n",
        "# NOTE: Operations between tensors must happen on the SAME device.\n",
        "# This would cause an error: large_tensor_cpu + large_tensor_gpu"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available! We'll use the GPU.\n",
            "\n",
            "large_tensor_cpu is on device: cpu\n",
            "large_tensor_gpu is on device: cuda:0\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdsiuarSDs4G"
      },
      "source": [
        "For large matrix multiplications, the speed difference between CPU and GPU is staggering—often 10x to 100x faster!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFPMY5LQDs4G"
      },
      "source": [
        "## **🏁 Summary**\n",
        "\n",
        "* **Tensors** are the central data structure.\n",
        "* You can **create, index, and operate** on tensors just like NumPy arrays.\n",
        "* Tensors are a powerful way to **represent AI concepts** like state spaces and utilities from your AIMA textbook.\n",
        "* The **`autograd`** engine is PyTorch's superpower, allowing for automatic gradient calculation, which is the key to optimization.\n",
        "* PyTorch can leverage **GPUs** to drastically speed up computations.\n",
        "\n",
        "These are the essential building blocks you will use as you move into more advanced topics like:\n",
        "* Optimization algorithms (like Gradient Descent).\n",
        "* Reinforcement Learning.\n",
        "* And eventually, Deep Learning and Neural Networks.\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-30T00:13:43.970317Z",
          "start_time": "2025-09-30T00:13:43.969123Z"
        },
        "id": "q1BkwzklDs4G"
      },
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}